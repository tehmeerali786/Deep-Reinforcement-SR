{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e720b132",
   "metadata": {},
   "source": [
    "# Playing Atari Games Using DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d18d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4397b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d755aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfc1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MsPacman-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027e135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = (88, 80, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ede9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215419f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f5bb6",
   "metadata": {},
   "source": [
    "## Preprocess the Game Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da06058",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.array([210, 164, 74]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e203458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_state(state):\n",
    "    \n",
    "    # crop and resize the image\n",
    "    image = state[1:176:2, ::2]\n",
    "    \n",
    "    # convert the image to greyscale\n",
    "    image = image.mean(axis=2)\n",
    "    \n",
    "    # improve image contrast\n",
    "    image[image==color] =0\n",
    "    \n",
    "    # normalize the image\n",
    "    image = (image - 128) / 128-1\n",
    "    \n",
    "    # reshape the image\n",
    "    image = np.expand_dims(image.reshape(88, 80, 1), axis=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b979d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \n",
    "        # define the state size\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        # define the action size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # define the replay buffer\n",
    "        self.reply_buffer = deque(maxlen=5000)\n",
    "        \n",
    "        # define the discount factor\n",
    "        self.gama = 0.9\n",
    "        \n",
    "        # define the epsilon value\n",
    "        self.epsilon = 0.8\n",
    "        \n",
    "        # define the update rate at which we want to update the target network\n",
    "        self.update_rate = 1000\n",
    "        \n",
    "        # define the main network\n",
    "        self.main_network = self.build_network()\n",
    "        \n",
    "        # define the target network\n",
    "        self.target_network = self.build_network()\n",
    "        \n",
    "        # copy the weights of the main network to the target network\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "        \n",
    "        \n",
    "    # let's define a function called build_network which is essentialy your DQN\n",
    "    \n",
    "    def build_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=4, padding='same', input_shape=self.state_size))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2D(64, (4, 4), strides=2, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "                  \n",
    "        model.add(Conv2D(64, (3, 3), strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "                  \n",
    "        model.compile(loss='mse', optimizer=Adam())\n",
    "                  \n",
    "        return model\n",
    "                  \n",
    "        \n",
    "    # we learned that in DQN, to take care of exploration-exploitation trade off, we select action\n",
    "    # using the epsilon-greedy policy. So, now we define the function called epsilon-greedy \n",
    "    # for selecting action using the epsilon-greedy policy.\n",
    "                  \n",
    "    def epsilon_greedy(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "              return np.random.randint(self.action_size)\n",
    "                  \n",
    "        Q_values = self.main_network.predict(state)\n",
    "                  \n",
    "        return np.argmax(Q_value[0])\\\n",
    "                  \n",
    "    # train the network\n",
    "                  \n",
    "    def train(self, batch_size):\n",
    "                  \n",
    "        # sample a mini batch of transition from the replay buffer\n",
    "        minibatch = random.sample(self.replay_buffer, batch_size)\n",
    "                  \n",
    "        # compute the Q value using the target network\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            if not done:\n",
    "                  target_Q = (reward, self.gamma * np.amax(self.target_network.predict(next_state)))\n",
    "            else:\n",
    "                  target_Q = reward\n",
    "                \n",
    "            # compute the Q value using the main nework\n",
    "            Q_values = self.main_network.predict(state)\n",
    "                  \n",
    "            Q_values[0][action] = target_Q\n",
    "                  \n",
    "            # train the main network\n",
    "            self.main_network.fit(state, Q_values, epochs=1, verbose=0)\n",
    "                  \n",
    "            \n",
    "    # update the target network weights by coping from the main network\n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "            \n",
    "                  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b289a7",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4949552",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "252c434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca09ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_screens = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e67775",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d11bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingFunctionException",
     "evalue": "glCreateShader is not exported by the available OpenGL driver.  OpenGL 2.0 is required for this functionality.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingFunctionException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TEHMEE~1\\AppData\\Local\\Temp/ipykernel_6416/310505979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# render the environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# update the timestep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"human\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimpleImageViewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             self.window = get_window(\n\u001b[0m\u001b[0;32m    418\u001b[0m                 \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mget_window\u001b[1;34m(width, height, display, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# create GL context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     return pyglet.window.Window(\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWin32Window\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchanges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\window\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, file_drops, display, screen, config, context, mode)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvisible\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\window\\__init__.py\u001b[0m in \u001b[0;36m_create_projection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         self._default_program = shader.ShaderProgram(\n\u001b[1;32m--> 590\u001b[1;33m             \u001b[0mshader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mShader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_vertex_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vertex'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m             shader.Shader(self._default_fragment_source, 'fragment'))\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\shader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, source_string, shader_type)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0msource_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshader_source_utf8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         \u001b[0mshader_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglCreateShader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshader_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[0mglShaderSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshader_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_buffer_pointer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[0mglCompileShader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshader_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\gl\\lib_wgl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeWGLFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyglet\\gl\\lib.py\u001b[0m in \u001b[0;36mMissingFunction\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmissing_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mMissingFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mMissingFunctionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mMissingFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingFunctionException\u001b[0m: glCreateShader is not exported by the available OpenGL driver.  OpenGL 2.0 is required for this functionality."
     ]
    }
   ],
   "source": [
    "done = False \n",
    "time_step = 0\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # set return to 0\n",
    "    Return = 0\n",
    "    \n",
    "    # preprocess the game screen\n",
    "    state = preprocess_state(env.reset())\n",
    "    \n",
    "    # for each step in the episode\n",
    "    for t in range(num_timesteps):\n",
    "        \n",
    "        # render the environment \n",
    "        env.render()\n",
    "        \n",
    "        # update the timestep\n",
    "        time_step = time_step + 1\n",
    "        \n",
    "        # update the target network\n",
    "        if time_step % dqn.update_rate == 0:\n",
    "            dqn.update_target_network\n",
    "        \n",
    "        # select the action\n",
    "        action = dqn.epsilon_greedy(state)\n",
    "        \n",
    "        # perform the selected action\n",
    "        next_state, reward, done, _ = evn.step(action)\n",
    "        \n",
    "        # preprocess the next state\n",
    "        next_state = preprocess_state(next_state)\n",
    "        \n",
    "        # store the transition information\n",
    "        dqn.store_transition(state, action, reward, next_state, done)\n",
    "        \n",
    "        # update current state to the next state\n",
    "        state = next_state\n",
    "        \n",
    "        # update the return\n",
    "        Return = Return + reward\n",
    "        \n",
    "        # if the episode is done then print the return \n",
    "        if done:\n",
    "            print('Episode :', i, ', ', 'Return', Return )\n",
    "            break\n",
    "            \n",
    "        # if the number of transition in the replay buffer is greater than batch size\n",
    "        # then train the network\n",
    "        if len(dqn.replay_buffer) > batch_size:\n",
    "            dqn.train(batch_size)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec8b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6bcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
