{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f57cf79",
   "metadata": {},
   "source": [
    "# Epsilon-Greedy Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da49e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_bandits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7caf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BanditTwoArmedHighLowFixed-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b7e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(env.p_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52f58bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46afb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_rewards = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3708645",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8944a9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80abd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16fc089",
   "metadata": {},
   "source": [
    "### Defining the Epsilon-Greedy Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d4f6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(epsilon):\n",
    "    \n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return np.argmax(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9190c",
   "metadata": {},
   "source": [
    "### Start Pulling the Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3041d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_rounds):\n",
    "    \n",
    "    # select the arm based on the epsilon-greedy method\n",
    "    arm = epsilon_greedy(0.5)\n",
    "    \n",
    "    # pull the arm and store the reward and next state information\n",
    "    next_state, reward, done, info = env.step(arm)\n",
    "    \n",
    "    # increment the count of the arm by 1\n",
    "    count[arm] = count[arm] + 1\n",
    "    \n",
    "    # update the sum of rewards\n",
    "    sum_rewards[arm] = sum_rewards[arm] + reward\n",
    "    \n",
    "    # update the average reward of the arm\n",
    "    Q[arm] = sum_rewards[arm] / count[arm]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef6cf781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83561644 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720d3a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is arm 1\n"
     ]
    }
   ],
   "source": [
    "print(f'The optimal arm is arm {np.argmax(Q) + 1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d206b",
   "metadata": {},
   "source": [
    "# Softmax Eploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d74fb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_bandits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46e7aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BanditTwoArmedHighLowFixed-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7efb086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(env.p_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2b1db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4f0ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_rewards = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e30b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e89c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cdf1a3",
   "metadata": {},
   "source": [
    "### Defining the Softmax Exploration Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a839d",
   "metadata": {},
   "source": [
    "Now, let's define the softmax function with temperature `T` as:\n",
    "\n",
    "$$P_t(a) = \\frac{\\text{exp}(Q_t(a)/T)} {\\sum_{i=1}^n \\text{exp}(Q_t(i)/T)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "224c1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(T):\n",
    "    \n",
    "    # compute the probability of each arm based on the above equation\n",
    "    denom = sum([np.exp(i/T) for i in Q])\n",
    "    probs = [np.exp(i/T)/denom for i in Q]\n",
    "    \n",
    "    # select the arm based on the computed probability distribution of arms\n",
    "    arm = np.random.choice(env.action_space.n, p=probs)\n",
    "    \n",
    "    return arm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0686121",
   "metadata": {},
   "source": [
    "### Start Pulling the Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b381e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59f4b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_rounds):\n",
    "    \n",
    "    # select the arm based on the softmax eploration method\n",
    "    arm = softmax(T)\n",
    "    \n",
    "    # pull the arm and store the reward and next state information\n",
    "    next_state, reward, done, info = env.step(arm)\n",
    "    \n",
    "    # increment the count of the arm by 1\n",
    "    count[arm] = count[arm] + 1\n",
    "    \n",
    "    # update the sum of rewards of the arm\n",
    "    sum_rewards[arm] = sum_rewards[arm] + reward\n",
    "    \n",
    "    # update the average reward of the arm\n",
    "    Q[arm] = sum_rewards[arm]/count[arm]\n",
    "    \n",
    "    # reduce the temprature \n",
    "    T = T * 0.99\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a92e16d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87755102 0.17647059]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db6845bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is arm 1\n"
     ]
    }
   ],
   "source": [
    "print(f'The optimal arm is arm {np.argmax(Q)+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06501e",
   "metadata": {},
   "source": [
    "# Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d85ee208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_bandits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecb17113",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BanditTwoArmedHighLowFixed-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce3e5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(env.p_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4b21580",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee289587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_rewards = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdf6898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cd1d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a1dc4f",
   "metadata": {},
   "source": [
    "### Defining the Upper Confidence Bound\n",
    "\n",
    "$$ \\text{UCB(a)} =Q(a) +\\sqrt{\\frac{2 \\log(t)}{N(a)}}  --- (1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6512e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCB(i):\n",
    "    \n",
    "    # initialize the numpy array for storing the UCB of all the arms\n",
    "    ucb = np.zeros(2)\n",
    "    \n",
    "    # before computing the UCB, we explore all the arms at least once, so for the first 2 rounds,\n",
    "    # we directly select the arm corresponding to the round number\n",
    "    \n",
    "    if i < 2:\n",
    "        return i\n",
    "    \n",
    "    # if the round is greater than 1 then, we compute the UCB of all the arms as specified in the\n",
    "    # equation(1) and return the arm which has the highest the UCB\n",
    "    \n",
    "    else:\n",
    "        for arm in range(2):\n",
    "            ucb[arm] = Q[arm] + np.sqrt((2*np.log(sum(count))) / count[arm])\n",
    "        return (np.argmax(ucb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014f281",
   "metadata": {},
   "source": [
    "### Start Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc397e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_rounds):\n",
    "    \n",
    "    # select the arm based on the UCB method\n",
    "    arm = UCB(i)\n",
    "    \n",
    "    # pull the arm and store the reward and next state information\n",
    "    next_state, reward, done, info = env.step(arm)\n",
    "    \n",
    "    # increment the count of the arm by 1\n",
    "    count[arm] = count[arm] + 1\n",
    "    \n",
    "    # update the sum of rewards of the arm\n",
    "    sum_rewards[arm] = sum_rewards[arm] + reward\n",
    "    \n",
    "    # update the average reward of the arm\n",
    "    Q[arm] = sum_rewards[arm] / count[arm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efd122c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7971a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal arm is arm 1\n"
     ]
    }
   ],
   "source": [
    "print(f'The optimal arm is arm {np.argmax(Q)+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1011ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
